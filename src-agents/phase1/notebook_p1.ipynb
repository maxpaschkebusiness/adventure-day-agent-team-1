{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Setting everything up\n",
    "\n",
    "Open this repository in a GitHub Codespace.\n",
    "Before you start with anything else, make sure you setup the infrastructure required. Follow the readme file in the root folder to do this!\n",
    "\n",
    "To start with Phase 1, if not already done run this in the top level folder:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://cog-ukzrhgnqdd2wy.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if stuff works in general, you can run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the feeling of connection and understanding between people. There's something truly magical about that shared moment of empathy and harmony. How about you?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = model_name,    \n",
    "    messages = [{\"role\" : \"assistant\", \"content\" : \"The one thing I love more than anything else is \"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the object model for receiving questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class QuestionType(str, Enum):\n",
    "    multiple_choice = \"multiple_choice\"\n",
    "    true_or_false = \"true_or_false\"\n",
    "    estimation = \"estimation\"\n",
    "\n",
    "class Ask(BaseModel):\n",
    "    question: str | None = None\n",
    "    type: QuestionType\n",
    "    correlationToken: str | None = None\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    correlationToken: str | None = None\n",
    "    promptTokensUsed: int | None = None\n",
    "    completionTokensUsed: int | None = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR Mission: \n",
    "Adjust the function below and reuse it in the main.py file later to deploy to Azure and to update your service. \n",
    "Ensure the answers provided are correct and in the correct format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_question(ask: Ask):\n",
    "    # \"\"\"\n",
    "    # # Ask a question\n",
    "    # \"\"\"\n",
    "\n",
    "    # Send a completion call to generate an answer\n",
    "    print('Sending a request to openai')\n",
    "    \n",
    "    start_phrase =  ask.question\n",
    "    response: openai.types.chat.chat_completion.ChatCompletion = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = deployment_name,\n",
    "        messages = [{\"role\" : \"assistant\", \"content\" : \"I'm a 5 year old and i have the following question. Please answer only in short answers:\" + start_phrase}, \n",
    "                     { \"role\" : \"system\", \"content\" : \"Answer this question with content only.\"}]\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    print(response)\n",
    "    answer = Answer(answer=response.choices[0].message.content)\n",
    "    answer.correlationToken = ask.correlationToken\n",
    "    answer.promptTokensUsed = response.usage.prompt_tokens\n",
    "    answer.completionTokensUsed = response.usage.completion_tokens\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this snippet to try your method with several questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending a request to openai\n",
      "The Wizard of Oz\n",
      "ChatCompletion(id='chatcmpl-A8OE7aXCkRE5e2LTbARt7PHMKftK4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Wizard of Oz', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726563115, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=4, prompt_tokens=82, total_tokens=86), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='The Wizard of Oz' correlationToken=None promptTokensUsed=82 completionTokensUsed=4\n",
      "Sending a request to openai\n",
      "False.\n",
      "ChatCompletion(id='chatcmpl-A8OE8KNwLT63e3flfunW8KN2nlnpB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='False.', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726563116, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=2, prompt_tokens=52, total_tokens=54), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='False.' correlationToken=None promptTokensUsed=52 completionTokensUsed=2\n",
      "Sending a request to openai\n",
      "Three movies.\n",
      "ChatCompletion(id='chatcmpl-A8OE8FcJyLqwUk0pUbOighls1FUBE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Three movies.', refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726563116, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=3, prompt_tokens=57, total_tokens=60), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer='Three movies.' correlationToken=None promptTokensUsed=57 completionTokensUsed=3\n",
      "Sending a request to openai\n",
      "That's tricky! The moon is super big, and beans are really small, so it would be a lot. More than you can count!\n",
      "ChatCompletion(id='chatcmpl-A8OE8kyVMZIfJ5zfc1YKJD3zZOUEN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"That's tricky! The moon is super big, and beans are really small, so it would be a lot. More than you can count!\", refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726563116, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b2ffeb16ee', usage=CompletionUsage(completion_tokens=28, prompt_tokens=47, total_tokens=75), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}])\n",
      "Answer: answer=\"That's tricky! The moon is super big, and beans are really small, so it would be a lot. More than you can count!\" correlationToken=None promptTokensUsed=47 completionTokensUsed=28\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "errors = 0\n",
    "\n",
    "def check_answer(answer, expected):\n",
    "    if answer != expected:\n",
    "        logging.error(f\"Got answer '{answer}', but expected '{expected}'\")\n",
    "    return 1\n",
    "ask = Ask(question=\"Which movie features a plot where a young girl named Dorothy is transported to a magical land via a tornado? 1) Cinderella 2) The Wizard of Oz 3) Alice in Wonderland 4) The Little Mermaid\", type=QuestionType.multiple_choice)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"The Wizard of Oz\")\n",
    "\n",
    "ask = Ask(question=\"Is Yoda a character from the Star Trek universe: True or False?\", type=QuestionType.true_or_false)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"false\")\n",
    "\n",
    "ask = Ask(question=\"How many movies are there in 'The Lord of the Rings' trilogy directed by Peter Jackson?\", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"3\")\n",
    "\n",
    "ask = Ask(question=\"How many states does the US have\", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"50\")\n",
    "\n",
    "ask = Ask(question=\"Is an apple a fruit?\", type=QuestionType.true_or_false)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"true\")\n",
    "\n",
    "ask = Ask(question=\"Who was the first president of the United States\", type=QuestionType.estimation)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"George Washington\")\n",
    "\n",
    "ask = Ask(question=\"Which animal is extinct? 1) Dog 2) T. Rex 3) Cat\", type=QuestionType.multiple_choice)\n",
    "answer = await ask_question(ask)\n",
    "errors+=check_answer(answer.answer, \"T. Rex\")\n",
    "\n",
    "\n",
    "if errors > 0:\n",
    "    raise Exception(f\"Got {errors} errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Questions\n",
    "Sample Questions could look like this. Make sure your answer exactly  matches the required answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "{\n",
    "    \"id\": 3,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Which movie features a plot where a young girl named Dorothy is transported to a magical land via a tornado? 1) Cinderella 2) The Wizard of Oz 3) Alice in Wonderland 4) The Little Mermaid\",\n",
    "    \"answer\": \"The Wizard of Oz\",\n",
    "    \"type\": \"multiple_choice\"\n",
    "},\n",
    "{\n",
    "    \"id\": 4,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"Is Yoda a character from the Star Trek universe: True or False?\",\n",
    "    \"answer\": false,\n",
    "    \"type\": \"true_or_false\"\n",
    "},\n",
    "{\n",
    "    \"id\": 5,\n",
    "    \"phase\": 1,\n",
    "    \"question\": \"How many movies are there in 'The Lord of the Rings' trilogy directed by Peter Jackson?\",\n",
    "    \"answer\": 3,\n",
    "    \"type\": \"estimation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you transfer your code changes into main.py (or additional files). \n",
    "You can test your app locally using uvicorn. (See Readme.md for details.)\n",
    "\n",
    "Then redeploy your container using this command.\n",
    "```\n",
    "bash ./azd-hooks/deploy.sh phase1 $AZURE_ENV_NAME\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
